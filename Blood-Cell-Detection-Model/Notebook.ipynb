{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9730743d",
   "metadata": {},
   "source": [
    "# Object Detection Project (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce91827",
   "metadata": {},
   "source": [
    "dataset:  https://github.com/Shenggan/BCCD_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd79ed",
   "metadata": {},
   "source": [
    "The purpose of this project is to train a RCNN that detects different\n",
    "blood cell types in an image and create a bounding box around\n",
    "the detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbefa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4eaf86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations==0.4.6\n",
      "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
      "     -------------------------------------- 117.2/117.2 kB 1.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from albumentations==0.4.6) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\envs\\tf\\lib\\site-packages (from albumentations==0.4.6) (1.7.3)\n",
      "Collecting imgaug>=0.4.0\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "     -------------------------------------- 948.0/948.0 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\anaconda\\envs\\tf\\lib\\site-packages (from albumentations==0.4.6) (6.0)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-win_amd64.whl (35.5 MB)\n",
      "     ---------------------------------------- 35.5/35.5 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: imageio in c:\\anaconda\\envs\\tf\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.22.4)\n",
      "Requirement already satisfied: six in c:\\anaconda\\envs\\tf\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\envs\\tf\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.5.2)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Collecting Shapely\n",
      "  Downloading Shapely-1.8.5.post1-cp37-cp37m-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.19.3)\n",
      "Requirement already satisfied: Pillow in c:\\anaconda\\envs\\tf\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda\\envs\\tf\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.3.0)\n",
      "Building wheels for collected packages: albumentations\n",
      "  Building wheel for albumentations (setup.py): started\n",
      "  Building wheel for albumentations (setup.py): finished with status 'done'\n",
      "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65162 sha256=7b81969b8695c004f269db82db495a3f272146322b7c70858b280f9abed6ad36\n",
      "  Stored in directory: c:\\users\\kanen\\appdata\\local\\pip\\cache\\wheels\\cf\\34\\0f\\cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
      "Successfully built albumentations\n",
      "Installing collected packages: Shapely, opencv-python-headless, opencv-python, imgaug, albumentations\n",
      "Successfully installed Shapely-1.8.5.post1 albumentations-0.4.6 imgaug-0.4.0 opencv-python-4.6.0.66 opencv-python-headless-4.6.0.66\n",
      "[WinError 2] The system cannot find the file specified: 'vision'\n",
      "C:\\Users\\kanen\\Desktop\\Python\\ML\\Blood-Cell-Detection-Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanen\\Desktop\\Python\\ML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe255b8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as torchtrans  \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4caa67",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f3d68a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  filename  cell_type  xmin  xmax  ymin  ymax\n",
      "0     BloodImage_00000.jpg        WBC   260   491   177   376\n",
      "1     BloodImage_00000.jpg        RBC    78   184   336   435\n",
      "2     BloodImage_00000.jpg        RBC    63   169   237   336\n",
      "3     BloodImage_00000.jpg        RBC   214   320   362   461\n",
      "4     BloodImage_00000.jpg        RBC   414   506   352   445\n",
      "...                    ...        ...   ...   ...   ...   ...\n",
      "4883  BloodImage_00410.jpg  Platelets   239   291   275   321\n",
      "4884  BloodImage_00410.jpg  Platelets   121   189   260   320\n",
      "4885  BloodImage_00410.jpg  Platelets    57   104   119   167\n",
      "4886  BloodImage_00410.jpg  Platelets     1    29   286   327\n",
      "4887  BloodImage_00410.jpg        WBC   367   611   166   394\n",
      "\n",
      "[4888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b353a",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab2e886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [_, 'Platelets', 'RBC', 'WBC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb60a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerically encode data labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(class_names)\n",
    "df['cell_type'] = le.transform(df['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4f5724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  filename  cell_type  xmin  xmax  ymin  ymax\n",
      "0     BloodImage_00000.jpg          3   260   491   177   376\n",
      "1     BloodImage_00000.jpg          2    78   184   336   435\n",
      "2     BloodImage_00000.jpg          2    63   169   237   336\n",
      "3     BloodImage_00000.jpg          2   214   320   362   461\n",
      "4     BloodImage_00000.jpg          2   414   506   352   445\n",
      "...                    ...        ...   ...   ...   ...   ...\n",
      "4883  BloodImage_00410.jpg          1   239   291   275   321\n",
      "4884  BloodImage_00410.jpg          1   121   189   260   320\n",
      "4885  BloodImage_00410.jpg          1    57   104   119   167\n",
      "4886  BloodImage_00410.jpg          1     1    29   286   327\n",
      "4887  BloodImage_00410.jpg          3   367   611   166   394\n",
      "\n",
      "[4888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize bounding box values\n",
    "imgWidth = 640\n",
    "imgHeight = 480\n",
    "print(df)\n",
    "df['xmin'] /= imgWidth\n",
    "df['xmax'] /= imgWidth\n",
    "df['ymin'] /= imgHeight\n",
    "df['ymax'] /= imgHeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "22466854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  filename  cell_type      xmin      xmax      ymin      ymax\n",
      "0     BloodImage_00000.jpg          3  0.406250  0.767188  0.368750  0.783333\n",
      "1     BloodImage_00000.jpg          2  0.121875  0.287500  0.700000  0.906250\n",
      "2     BloodImage_00000.jpg          2  0.098437  0.264062  0.493750  0.700000\n",
      "3     BloodImage_00000.jpg          2  0.334375  0.500000  0.754167  0.960417\n",
      "4     BloodImage_00000.jpg          2  0.646875  0.790625  0.733333  0.927083\n",
      "...                    ...        ...       ...       ...       ...       ...\n",
      "4883  BloodImage_00410.jpg          1  0.373437  0.454688  0.572917  0.668750\n",
      "4884  BloodImage_00410.jpg          1  0.189062  0.295312  0.541667  0.666667\n",
      "4885  BloodImage_00410.jpg          1  0.089063  0.162500  0.247917  0.347917\n",
      "4886  BloodImage_00410.jpg          1  0.001563  0.045312  0.595833  0.681250\n",
      "4887  BloodImage_00410.jpg          3  0.573438  0.954688  0.345833  0.820833\n",
      "\n",
      "[4888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d9b275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7249d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "imgNames = pd.unique(df['filename'])\n",
    "imgDirectory = ('BCCD\\\\JPEGImages\\\\')\n",
    "\n",
    "imgs = np.zeros([len(imgNames), imgHeight, imgWidth, 3])\n",
    "for idx, imgName in enumerate(imgNames):\n",
    "    imgs[idx, :, :, :] = cv2.imread(imgDirectory + imgName)\n",
    "    \n",
    "print(np.shape(imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e761882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(imgNames)\n",
    "df['imgs_idx'] = le.transform(df['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a646a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  filename  cell_type      xmin      xmax      ymin      ymax  \\\n",
      "0     BloodImage_00000.jpg          3  0.406250  0.767188  0.368750  0.783333   \n",
      "1     BloodImage_00000.jpg          2  0.121875  0.287500  0.700000  0.906250   \n",
      "2     BloodImage_00000.jpg          2  0.098437  0.264062  0.493750  0.700000   \n",
      "3     BloodImage_00000.jpg          2  0.334375  0.500000  0.754167  0.960417   \n",
      "4     BloodImage_00000.jpg          2  0.646875  0.790625  0.733333  0.927083   \n",
      "...                    ...        ...       ...       ...       ...       ...   \n",
      "4883  BloodImage_00410.jpg          1  0.373437  0.454688  0.572917  0.668750   \n",
      "4884  BloodImage_00410.jpg          1  0.189062  0.295312  0.541667  0.666667   \n",
      "4885  BloodImage_00410.jpg          1  0.089063  0.162500  0.247917  0.347917   \n",
      "4886  BloodImage_00410.jpg          1  0.001563  0.045312  0.595833  0.681250   \n",
      "4887  BloodImage_00410.jpg          3  0.573438  0.954688  0.345833  0.820833   \n",
      "\n",
      "      imgs_idx  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "...        ...  \n",
      "4883       363  \n",
      "4884       363  \n",
      "4885       363  \n",
      "4886       363  \n",
      "4887       363  \n",
      "\n",
      "[4888 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e8198",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ad58162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# Flip images upside down\n",
    "imgsFlipped = np.array(imgs, copy=True)  \n",
    "print(np.shape(imgsFlipped))\n",
    "for idx, img in enumerate(imgsFlipped):\n",
    "    imgsFlipped[idx, :, :, :] = np.flipud(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "29f90d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirror images along y-axis\n",
    "imgsMirrored = np.array(imgs, copy=True)\n",
    "for idx, img in enumerate(imgsMirrored):\n",
    "    imgsMirrored[idx, :, :, :] = np.fliplr(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e91a2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1092, 480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "imgShape = np.shape(imgs[0])\n",
    "\n",
    "# Combine all images and augmented images into one numpy array\n",
    "imgsAll = np.zeros([len(imgs)*3, imgShape[0], imgShape[1], imgShape[2]])\n",
    "imgsAll[:len(imgs), :, :, :] = imgs\n",
    "imgsAll[len(imgs):len(imgs)*2, :, :, :] = imgsFlipped\n",
    "imgsAll[len(imgs)*2:len(imgs)*3, :, :, :] = imgsMirrored\n",
    "\n",
    "print(np.shape(imgsAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "92b977e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cell_type      xmin      xmax      ymin      ymax  imgs_idx\n",
      "0             3  0.406250  0.767188  0.368750  0.783333         0\n",
      "1             2  0.121875  0.287500  0.700000  0.906250         0\n",
      "2             2  0.098437  0.264062  0.493750  0.700000         0\n",
      "3             2  0.334375  0.500000  0.754167  0.960417         0\n",
      "4             2  0.646875  0.790625  0.733333  0.927083         0\n",
      "...         ...       ...       ...       ...       ...       ...\n",
      "4883          1  0.373437  0.454688  0.572917  0.668750       363\n",
      "4884          1  0.189062  0.295312  0.541667  0.666667       363\n",
      "4885          1  0.089063  0.162500  0.247917  0.347917       363\n",
      "4886          1  0.001563  0.045312  0.595833  0.681250       363\n",
      "4887          3  0.573438  0.954688  0.345833  0.820833       363\n",
      "\n",
      "[4888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['filename'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fec010c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cell_type      xmin      xmax      ymin      ymax  imgs_idx\n",
      "0             3  0.406250  0.767188  0.216667  0.631250       364\n",
      "1             2  0.121875  0.287500  0.093750  0.300000       364\n",
      "2             2  0.098437  0.264062  0.300000  0.506250       364\n",
      "3             2  0.334375  0.500000  0.039583  0.245833       364\n",
      "4             2  0.646875  0.790625  0.072917  0.266667       364\n",
      "...         ...       ...       ...       ...       ...       ...\n",
      "4883          1  0.373437  0.454688  0.331250  0.427083       727\n",
      "4884          1  0.189062  0.295312  0.333333  0.458333       727\n",
      "4885          1  0.089063  0.162500  0.652083  0.752083       727\n",
      "4886          1  0.001563  0.045312  0.318750  0.404167       727\n",
      "4887          3  0.573438  0.954688  0.179167  0.654167       727\n",
      "\n",
      "[4888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adjust bounding box to flip\n",
    "dfFlipped = df.copy(deep=True)\n",
    "dfFlipped['ymin'] = 1 - df['ymax']\n",
    "dfFlipped['ymax'] = 1 - df['ymin']\n",
    "dfFlipped['imgs_idx'] = df['imgs_idx'] + len(imgs)\n",
    "print(dfFlipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fea07a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cell_type      xmin      xmax      ymin      ymax  imgs_idx\n",
      "0             3  0.232812  0.593750  0.368750  0.783333       728\n",
      "1             2  0.712500  0.878125  0.700000  0.906250       728\n",
      "2             2  0.735938  0.901563  0.493750  0.700000       728\n",
      "3             2  0.500000  0.665625  0.754167  0.960417       728\n",
      "4             2  0.209375  0.353125  0.733333  0.927083       728\n",
      "...         ...       ...       ...       ...       ...       ...\n",
      "4883          1  0.545312  0.626563  0.572917  0.668750      1091\n",
      "4884          1  0.704688  0.810937  0.541667  0.666667      1091\n",
      "4885          1  0.837500  0.910937  0.247917  0.347917      1091\n",
      "4886          1  0.954688  0.998437  0.595833  0.681250      1091\n",
      "4887          3  0.045312  0.426562  0.345833  0.820833      1091\n",
      "\n",
      "[4888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adjust bounding box to mirroring\n",
    "dfMirrored = df.copy(deep=True)\n",
    "dfMirrored['xmin'] = 1 - df['xmax']\n",
    "dfMirrored['xmax'] = 1 - df['xmin']\n",
    "dfMirrored['imgs_idx'] = dfFlipped['imgs_idx'] + len(imgs)\n",
    "print(dfMirrored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8fc16cdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cell_type      xmin      xmax      ymin      ymax  imgs_idx\n",
      "0              3  0.406250  0.767188  0.368750  0.783333         0\n",
      "1              2  0.121875  0.287500  0.700000  0.906250         0\n",
      "2              2  0.098437  0.264062  0.493750  0.700000         0\n",
      "3              2  0.334375  0.500000  0.754167  0.960417         0\n",
      "4              2  0.646875  0.790625  0.733333  0.927083         0\n",
      "...          ...       ...       ...       ...       ...       ...\n",
      "14659          1  0.545312  0.626563  0.572917  0.668750      1091\n",
      "14660          1  0.704688  0.810937  0.541667  0.666667      1091\n",
      "14661          1  0.837500  0.910937  0.247917  0.347917      1091\n",
      "14662          1  0.954688  0.998437  0.595833  0.681250      1091\n",
      "14663          3  0.045312  0.426562  0.345833  0.820833      1091\n",
      "\n",
      "[14664 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "dfAll = pd.concat([df, dfFlipped, dfMirrored], ignore_index=True)\n",
    "print(dfAll)\n",
    "imgs = imgsAll\n",
    "df = dfAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25914300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "# Function to show image with bounding boxes\n",
    "def plot_boxes(img, boxes):\n",
    "    imgHeight, imgWidth = np.shape(img)[0], np.shape(img)[1]\n",
    "    \n",
    "    fig, a = plt.subplots(1,1)\n",
    "    fig.set_size_inches(5,5)\n",
    "    a.imshow(img)\n",
    "    \n",
    "    #Draw red box for red blood cell, white for white blood cell, and blue for platelet\n",
    "    for box in boxes:\n",
    "        if box[4] == 1:\n",
    "            width = (box[1]-box[0])*imgWidth\n",
    "            height = (box[3]-box[2])*imgHeight\n",
    "            rect = patches.Rectangle(\n",
    "                (box[0]*imgWidth, box[2]*imgHeight),\n",
    "                width, height,\n",
    "                linewidth = 2,\n",
    "                edgecolor = 'b',\n",
    "                facecolor = 'none'\n",
    "            )\n",
    "        if box[4] == 2:\n",
    "            width = (box[1]-box[0])*imgWidth\n",
    "            height = (box[3]-box[2])*imgHeight\n",
    "            rect = patches.Rectangle(\n",
    "                (box[0]*imgWidth, box[2]*imgHeight),\n",
    "                width, height,\n",
    "                linewidth = 2,\n",
    "                edgecolor = 'r',\n",
    "                facecolor = 'none'\n",
    "            )\n",
    "        if box[4] == 3:\n",
    "            width = (box[1]-box[0])*imgWidth\n",
    "            height = (box[3]-box[2])*imgHeight\n",
    "            rect = patches.Rectangle(\n",
    "                (box[0]*imgWidth, box[2]*imgHeight),\n",
    "                width, height,\n",
    "                linewidth = 2,\n",
    "                edgecolor = 'w',\n",
    "                facecolor = 'none'\n",
    "            )\n",
    "    # Draw the bounding box on top of the image\n",
    "        a.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f318ba",
   "metadata": {},
   "source": [
    "Demonstrated the data augmentation by showing the regular image and the flipped and mirrored versions.\n",
    "The bounding box for the red blood cell is red, white for the white blood cell, and blue for platelets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1696c090",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-89bde5783132>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'imgs_idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xmin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'xmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ymin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ymax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cell_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(boxes)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgsAll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 15\n",
    "boxes = df.where(df['imgs_idx']==idx)[['xmin', 'xmax', 'ymin', 'ymax', 'cell_type']].dropna().to_numpy()\n",
    "#print(boxes)\n",
    "plot_boxes(cv2.cvtColor(imgsAll[idx].astype('uint8'), cv2.COLOR_BGR2RGB), boxes, )\n",
    "\n",
    "boxes = df.where(df['imgs_idx']==idx+364)[['xmin', 'xmax', 'ymin', 'ymax', 'cell_type']].dropna().to_numpy()\n",
    "plot_boxes(cv2.cvtColor(imgsAll[idx+364].astype('uint8'), cv2.COLOR_BGR2RGB), boxes)\n",
    "\n",
    "boxes = df.where(df['imgs_idx']==idx+728)[['xmin', 'xmax', 'ymin', 'ymax', 'cell_type']].dropna().to_numpy()\n",
    "plot_boxes(cv2.cvtColor(imgsAll[idx+728].astype('uint8'), cv2.COLOR_BGR2RGB), boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01f035",
   "metadata": {},
   "source": [
    "### Dataset and Dataset loader class\n",
    "Pytorch requires a class to process the data to the correct format and a dataset loader class which feeds the model the data for training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgsAll\n",
    "df = dfAll\n",
    "\n",
    "# we create a Dataset class which has a __getitem__ function and a __len__ function\n",
    "class BloodCellDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, width, height, classes, transforms=None):\n",
    "    self.transforms = transforms\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    \n",
    "    # sorting the images for consistency\n",
    "    # To get images, the extension of the filename is checked to be jpg\n",
    "    # classes: 0 index is reserved for background\n",
    "    self.classes = classes\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # reading the images and converting them to correct size and color    \n",
    "    img_rgb = cv2.cvtColor(imgs[idx], cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    img_res = cv2.resize(img_rgb, (self.width, self.height), cv2.INTER_AREA)\n",
    "    # diving by 255\n",
    "    img_res /= 255.0\n",
    "    \n",
    "    # annotation file\n",
    "    annot_filename = img_name[:-4] + '.txt'\n",
    "    annot_file_path = os.path.join(self.files_dir, annot_filename)\n",
    "    \n",
    "    boxes = df.where(df['imgs_idx']==idx)[\n",
    "        ['xmin', 'xmax', 'ymin', 'ymax'].dropna().to_numpy()\n",
    "    labels = df.where(df['imgs_idx']==idx)['cell_type'].dropna().to_numpy()\n",
    "    \n",
    "    # cv2 image gives size as height x width\n",
    "    imageWidth = img.shape[1]\n",
    "    imageHeight = img.shape[0]\n",
    "    \n",
    "    \n",
    "    # convert boxes into a torch.Tensor\n",
    "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "    \n",
    "    # getting the areas of the boxes\n",
    "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "    # suppose all instances are not crowd\n",
    "    iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "    \n",
    "    labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "    target = {}\n",
    "    target[\"boxes\"] = boxes\n",
    "    target[\"labels\"] = labels\n",
    "    target[\"area\"] = area\n",
    "    target[\"iscrowd\"] = iscrowd\n",
    "    image_id = torch.tensor([idx])\n",
    "    target[\"image_id\"] = image_id\n",
    "\n",
    "    if self.transforms:\n",
    "      sample = self.transforms(image = img_res,\n",
    "                                bboxes = target['boxes'],\n",
    "                                labels = labels)\n",
    "      img_res = sample['image']\n",
    "      target['boxes'] = torch.Tensor(sample['bboxes'])\n",
    "        \n",
    "    return img_res, target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)\n",
    "\n",
    "\n",
    "# check dataset\n",
    "dataset = BloodCellDataset(files_dir, 224, 224)\n",
    "print('Length of dataset:', len(dataset), '\\n')\n",
    "\n",
    "# getting the image and target for a test index.  Feel free to change the index.\n",
    "img, target = dataset[78]\n",
    "print('Image shape:', img.shape)\n",
    "print('Label example:', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a23f83",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c64c0",
   "metadata": {},
   "source": [
    "For this project I am using the SSD MobileNet V2 FPNLite 640x640 pre-trained model since\n",
    "it is lightweight and the data input size is relatively close to the sizes of the images \n",
    "being used for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f9a34ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20580\\3636497433.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python\\ML\\Blood-Cell-Detection-Model\\mrcnn\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mProposalLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     \"\"\"Receives anchor scores and selects a subset to pass as proposals\n\u001b[0;32m    257\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msecond\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mFiltering\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdone\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0manchor\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KE' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbdf84bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20580\\3070986822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'checkpoint/ckpt-0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mconfigs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_configs_from_pipeline_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config_util' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c8b5b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12162fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
